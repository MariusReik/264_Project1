{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1 â€“ Decision Trees and Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports\n",
    "Imports og random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from itertools import product\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from decision_tree import DecisionTree\n",
    "from random_forest import RandomForest\n",
    "\n",
    "# Reproducibility\n",
    "np.random.seed(21)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset\n",
    "\n",
    "Laster inn letters.csv og deler opp i features (X) og labels (y), og deler inn i test/train datasett (80/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1600, 16), y_train shape: (1600,)\n",
      "X_test shape: (400, 16), y_test shape: (400,)\n"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt(\"letters.csv\", delimiter=\",\", dtype=float, names=True)\n",
    "\n",
    "feature_names = list(data.dtype.names[:-1])\n",
    "target_name = data.dtype.names[-1]\n",
    "\n",
    "X = np.array([data[f] for f in feature_names]).T\n",
    "y = data[target_name].astype(int)\n",
    "\n",
    "# 80/20 train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=0, shuffle=True, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparametere\n",
    "\n",
    "Setter opp verdier som skal testes i grid search for DecisionTree og RandomForest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_params = {\n",
    "    \"criterion\": [\"entropy\", \"gini\"],\n",
    "    \"max_depth\": [None, 5, 10, 20],\n",
    "    \"max_features\": [None, \"sqrt\", \"log2\"],\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    \"n_estimators\": [10, 20, 40],\n",
    "    \"max_depth\": [5, 10, None],\n",
    "    \"criterion\": [\"entropy\", \"gini\"],\n",
    "    \"max_features\": [\"sqrt\", \"log2\"],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation\n",
    "\n",
    "Funksjon for k-fold cross validation som regner ut accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_score_custom(model_class, params, X, y, k=5, seed=0):\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=seed)\n",
    "    scores = []\n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        X_tr, X_val = X[train_idx], X[val_idx]\n",
    "        y_tr, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = model_class(**params)\n",
    "        model.fit(X_tr, y_tr)\n",
    "        y_pred = model.predict(X_val)\n",
    "        scores.append(accuracy_score(y_val, y_pred))\n",
    "    return float(np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTree grid search\n",
    "\n",
    "Tester kombinasjoner av hyperparametere og finner beste for DecisionTree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best DecisionTree params: {'criterion': 'gini', 'max_depth': 20, 'max_features': None}\n",
      "Best DecisionTree 5-fold CV accuracy: 0.8975\n"
     ]
    }
   ],
   "source": [
    "best_dt_params = None\n",
    "best_dt_score = -1.0\n",
    "\n",
    "for criterion, max_depth, max_features in product(\n",
    "    dt_params[\"criterion\"], dt_params[\"max_depth\"], dt_params[\"max_features\"]\n",
    "):\n",
    "    params = {\n",
    "        \"criterion\": criterion,\n",
    "        \"max_depth\": max_depth,\n",
    "        \"max_features\": max_features,\n",
    "    }\n",
    "    score = cross_val_score_custom(DecisionTree, params, X_train, y_train, k=5, seed=0)\n",
    "    if score > best_dt_score:\n",
    "        best_dt_score = score\n",
    "        best_dt_params = params\n",
    "\n",
    "print(\"Best DecisionTree params:\", best_dt_params)\n",
    "print(\"Best DecisionTree 5-fold CV accuracy:\", round(best_dt_score, 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForset - grid Serach\n",
    "Tester kombinasjoner av hyperparametere og finner beste for RandomForest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RandomForest params: {'n_estimators': 40, 'max_depth': None, 'criterion': 'entropy', 'max_features': 'sqrt'}\n",
      "Best RandomForest 5-fold CV accuracy: 0.965\n"
     ]
    }
   ],
   "source": [
    "best_rf_params = None\n",
    "best_rf_score = -1.0\n",
    "\n",
    "for n_estimators, max_depth, criterion, max_features in product(\n",
    "    rf_params[\"n_estimators\"],\n",
    "    rf_params[\"max_depth\"],\n",
    "    rf_params[\"criterion\"],\n",
    "    rf_params[\"max_features\"],\n",
    "):\n",
    "    params = {\n",
    "        \"n_estimators\": n_estimators,\n",
    "        \"max_depth\": max_depth,\n",
    "        \"criterion\": criterion,\n",
    "        \"max_features\": max_features,\n",
    "    }\n",
    "    score = cross_val_score_custom(RandomForest, params, X_train, y_train, k=5, seed=0)\n",
    "    if score > best_rf_score:\n",
    "        best_rf_score = score\n",
    "        best_rf_params = params\n",
    "\n",
    "print(\"Best RandomForest params:\", best_rf_params)\n",
    "print(\"Best RandomForest 5-fold CV accuracy:\", round(best_rf_score, 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final evaluation\n",
    "\n",
    "We retrain our models with the best hyperparameters on the full training set and evaluate on the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom DecisionTree test accuracy: 0.895\n",
      "Custom RandomForest test accuracy: 0.9775\n"
     ]
    }
   ],
   "source": [
    "# DecisionTree\n",
    "dt_best = DecisionTree(**best_dt_params)\n",
    "dt_best.fit(X_train, y_train)\n",
    "dt_test_acc = accuracy_score(y_test, dt_best.predict(X_test))\n",
    "\n",
    "# RandomForest\n",
    "rf_best = RandomForest(**best_rf_params)\n",
    "rf_best.fit(X_train, y_train)\n",
    "rf_test_acc = accuracy_score(y_test, rf_best.predict(X_test))\n",
    "\n",
    "print(\"Custom DecisionTree test accuracy:\", dt_test_acc)\n",
    "print(\"Custom RandomForest test accuracy:\", rf_test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trene beste modeller \n",
    "Trener beste modeler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom DecisionTree test accuracy: 0.9\n",
      "Custom RandomForest test accuracy: 0.9825\n"
     ]
    }
   ],
   "source": [
    "# DecisionTree (custom)\n",
    "dt_best = DecisionTree(**best_dt_params)\n",
    "dt_best.fit(X_train, y_train)\n",
    "dt_test_pred = dt_best.predict(X_test)\n",
    "dt_test_acc = accuracy_score(y_test, dt_test_pred)\n",
    "\n",
    "# RandomForest (custom)\n",
    "rf_best = RandomForest(**best_rf_params)\n",
    "rf_best.fit(X_train, y_train)\n",
    "rf_test_pred = rf_best.predict(X_test)\n",
    "rf_test_acc = accuracy_score(y_test, rf_test_pred)\n",
    "\n",
    "print(\"Custom DecisionTree test accuracy:\", round(dt_test_acc, 4))\n",
    "print(\"Custom RandomForest test accuracy:\", round(rf_test_acc, 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKLearn modeller\n",
    "\n",
    "Trener modell med sklearn med de samme paramterene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn DecisionTree test accuracy: 0.94\n",
      "Sklearn RandomForest test accuracy: 0.985\n"
     ]
    }
   ],
   "source": [
    "# Sklearn DecisionTree\n",
    "sk_dt = DecisionTreeClassifier(\n",
    "    criterion=best_dt_params[\"criterion\"],\n",
    "    max_depth=best_dt_params[\"max_depth\"],\n",
    "    max_features=best_dt_params[\"max_features\"],\n",
    "    random_state=0,\n",
    ")\n",
    "sk_dt.fit(X_train, y_train)\n",
    "sk_dt_acc = accuracy_score(y_test, sk_dt.predict(X_test))\n",
    "\n",
    "# Sklearn RandomForest\n",
    "sk_rf = RandomForestClassifier(\n",
    "    n_estimators=best_rf_params[\"n_estimators\"],\n",
    "    max_depth=best_rf_params[\"max_depth\"],\n",
    "    criterion=best_rf_params[\"criterion\"],\n",
    "    max_features=best_rf_params[\"max_features\"],\n",
    "    random_state=0,\n",
    ")\n",
    "sk_rf.fit(X_train, y_train)\n",
    "sk_rf_acc = accuracy_score(y_test, sk_rf.predict(X_test))\n",
    "\n",
    "print(\"Sklearn DecisionTree test accuracy:\", round(sk_dt_acc, 4))\n",
    "print(\"Sklearn RandomForest test accuracy:\", round(sk_rf_acc, 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rapport \n",
    "Detaljert evaluering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Custom DecisionTree ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9500    0.8906    0.9194        64\n",
      "           1     0.8219    0.8696    0.8451        69\n",
      "           2     0.9688    0.9538    0.9612        65\n",
      "           3     0.8806    0.8806    0.8806        67\n",
      "           4     0.9344    0.8906    0.9120        64\n",
      "           5     0.8667    0.9155    0.8904        71\n",
      "\n",
      "    accuracy                         0.9000       400\n",
      "   macro avg     0.9037    0.9001    0.9014       400\n",
      "weighted avg     0.9020    0.9000    0.9005       400\n",
      "\n",
      "Confusion matrix:\n",
      " [[57  0  2  2  0  3]\n",
      " [ 0 60  0  3  4  2]\n",
      " [ 0  2 62  0  0  1]\n",
      " [ 0  6  0 59  0  2]\n",
      " [ 3  1  0  1 57  2]\n",
      " [ 0  4  0  2  0 65]]\n",
      "\n",
      "=== Custom RandomForest ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        64\n",
      "           1     0.9583    1.0000    0.9787        69\n",
      "           2     0.9692    0.9692    0.9692        65\n",
      "           3     1.0000    1.0000    1.0000        67\n",
      "           4     0.9683    0.9531    0.9606        64\n",
      "           5     1.0000    0.9718    0.9857        71\n",
      "\n",
      "    accuracy                         0.9825       400\n",
      "   macro avg     0.9826    0.9824    0.9824       400\n",
      "weighted avg     0.9827    0.9825    0.9825       400\n",
      "\n",
      "Confusion matrix:\n",
      " [[64  0  0  0  0  0]\n",
      " [ 0 69  0  0  0  0]\n",
      " [ 0  0 63  0  2  0]\n",
      " [ 0  0  0 67  0  0]\n",
      " [ 0  1  2  0 61  0]\n",
      " [ 0  2  0  0  0 69]]\n",
      "\n",
      "=== Sklearn DecisionTree ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9531    0.9760        64\n",
      "           1     0.8919    0.9565    0.9231        69\n",
      "           2     0.9524    0.9231    0.9375        65\n",
      "           3     0.9538    0.9254    0.9394        67\n",
      "           4     0.9104    0.9531    0.9313        64\n",
      "           5     0.9429    0.9296    0.9362        71\n",
      "\n",
      "    accuracy                         0.9400       400\n",
      "   macro avg     0.9419    0.9401    0.9406       400\n",
      "weighted avg     0.9414    0.9400    0.9403       400\n",
      "\n",
      "Confusion matrix:\n",
      " [[61  0  0  2  0  1]\n",
      " [ 0 66  0  1  0  2]\n",
      " [ 0  0 60  0  4  1]\n",
      " [ 0  4  1 62  0  0]\n",
      " [ 0  1  2  0 61  0]\n",
      " [ 0  3  0  0  2 66]]\n",
      "\n",
      "=== Sklearn RandomForest ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        64\n",
      "           1     0.9583    1.0000    0.9787        69\n",
      "           2     0.9846    0.9846    0.9846        65\n",
      "           3     0.9853    1.0000    0.9926        67\n",
      "           4     0.9841    0.9688    0.9764        64\n",
      "           5     1.0000    0.9577    0.9784        71\n",
      "\n",
      "    accuracy                         0.9850       400\n",
      "   macro avg     0.9854    0.9852    0.9851       400\n",
      "weighted avg     0.9853    0.9850    0.9850       400\n",
      "\n",
      "Confusion matrix:\n",
      " [[64  0  0  0  0  0]\n",
      " [ 0 69  0  0  0  0]\n",
      " [ 0  0 64  0  1  0]\n",
      " [ 0  0  0 67  0  0]\n",
      " [ 0  1  1  0 62  0]\n",
      " [ 0  2  0  1  0 68]]\n"
     ]
    }
   ],
   "source": [
    "def report(name, y_true, y_pred):\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(classification_report(y_true, y_pred, digits=4))\n",
    "    print(\"Confusion matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "\n",
    "report(\"Custom DecisionTree\", y_test, dt_test_pred)\n",
    "report(\"Custom RandomForest\", y_test, rf_test_pred)\n",
    "report(\"Sklearn DecisionTree\", y_test, sk_dt.predict(X_test))\n",
    "report(\"Sklearn RandomForest\", y_test, sk_rf.predict(X_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (INF264)",
   "language": "python",
   "name": "inf264"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
