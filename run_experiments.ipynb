{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1 – Decision Trees and Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports\n",
    "Imports og random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from decision_tree import DecisionTree\n",
    "from random_forest import RandomForest\n",
    "\n",
    "# random seed\n",
    "RANDOM_SEED = 21\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset\n",
    "\n",
    "Laster inn letters.csv og deler opp i features (X) og labels (y), og deler inn i test/train datasett (80/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt(\"letters.csv\", delimiter=\",\", dtype=float, names=True)\n",
    "\n",
    "feature_names = list(data.dtype.names[:-1])\n",
    "target_name = data.dtype.names[-1]\n",
    "\n",
    "X = np.array([data[f] for f in feature_names]).T\n",
    "y = data[target_name].astype(int)\n",
    "\n",
    "# 80/20 train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=0, shuffle=True, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "print(f\"Feature columns names: {feature_names}\")\n",
    "print(f\"Target column name: {target_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparametere\n",
    "\n",
    "Setter opp verdier som skal testes i grid search for DecisionTree og RandomForest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_params = {\n",
    "    \"criterion\": [\"entropy\", \"gini\"],\n",
    "    \"max_depth\": [3, 5, 10, 15],\n",
    "    \"max_features\": [\"sqrt\", \"log2\"],\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    \"n_estimators\": [20, 30, 40],\n",
    "    \"max_depth\": [3, 5, 10, 15],\n",
    "    \"criterion\": [\"entropy\", \"gini\"],\n",
    "    \"max_features\": [\"sqrt\", \"log2\"],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation\n",
    "\n",
    "Funksjon for k-fold cross validation som regner ut accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_score(model_class, params, X, y, k=5, seed=RANDOM_SEED):\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=seed)\n",
    "    scores = []\n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        X_tr, X_val = X[train_idx], X[val_idx]\n",
    "        y_tr, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = model_class(**params)\n",
    "        model.fit(X_tr, y_tr)\n",
    "        y_pred = model.predict(X_val)\n",
    "        scores.append(accuracy_score(y_val, y_pred))\n",
    "    return float(np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTree grid search\n",
    "\n",
    "Tester kombinasjoner av hyperparametere og finner beste for DecisionTree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dt = []\n",
    "best_dt_params = None\n",
    "best_dt_score = -1.0\n",
    "\n",
    "for criterion, max_depth, max_features in product(\n",
    "    dt_params[\"criterion\"], dt_params[\"max_depth\"], dt_params[\"max_features\"]\n",
    "):\n",
    "    params = {\n",
    "        \"criterion\": criterion,\n",
    "        \"max_depth\": max_depth,\n",
    "        \"max_features\": max_features,\n",
    "    }\n",
    "    score = cross_val_score(\n",
    "        DecisionTree, params, X_train, y_train, k=5, seed=RANDOM_SEED\n",
    "    )\n",
    "    mean_score = np.mean(score)\n",
    "\n",
    "    # lagre alle resultater\n",
    "    results_dt.append({**params, \"cv_score\": mean_score})\n",
    "\n",
    "    # oppdater best score\n",
    "    if mean_score > best_dt_score:\n",
    "        best_dt_score = mean_score\n",
    "        best_dt_params = params\n",
    "\n",
    "df_dt_results = pd.DataFrame(results_dt).sort_values(by=\"cv_score\", ascending=False)\n",
    "\n",
    "print(\"Best DecisionTree params:\", best_dt_params)\n",
    "print(\"Best DecisionTree 5-fold CV accuracy:\", round(best_dt_score, 4))\n",
    "df_dt_results.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForset - grid Serach\n",
    "Tester kombinasjoner av hyperparametere og finner beste for RandomForest. (approx 6 min runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_rf = []\n",
    "best_rf_params = None\n",
    "best_rf_score = -1.0\n",
    "\n",
    "for n_estimators, max_depth, criterion, max_features in product(\n",
    "    rf_params[\"n_estimators\"],\n",
    "    rf_params[\"max_depth\"],\n",
    "    rf_params[\"criterion\"],\n",
    "    rf_params[\"max_features\"],\n",
    "):\n",
    "    params = {\n",
    "        \"n_estimators\": n_estimators,\n",
    "        \"max_depth\": max_depth,\n",
    "        \"criterion\": criterion,\n",
    "        \"max_features\": max_features,\n",
    "    }\n",
    "    score = cross_val_score(\n",
    "        RandomForest, params, X_train, y_train, k=5, seed=RANDOM_SEED\n",
    "    )\n",
    "    mean_score = np.mean(score)\n",
    "\n",
    "    # lagre alle resultater\n",
    "    results_rf.append({**params, \"cv_score\": mean_score})\n",
    "\n",
    "    # oppdater best score\n",
    "    if mean_score > best_rf_score:\n",
    "        best_rf_score = mean_score\n",
    "        best_rf_params = params\n",
    "\n",
    "df_rf_results = pd.DataFrame(results_rf).sort_values(by=\"cv_score\", ascending=False)\n",
    "\n",
    "print(\"Best RandomForest params:\", best_rf_params)\n",
    "print(\"Best RandomForest 5-fold CV accuracy:\", round(best_rf_score, 4))\n",
    "df_rf_results.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTree accuracy vs max_depth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = [1, 2, 5, 10, 20, None]\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for d in depths:\n",
    "    model = DecisionTree(max_depth=d, criterion=\"gini\", max_features=\"sqrt\")\n",
    "    model.fit(X_train, y_train)\n",
    "    train_scores.append(accuracy_score(y_train, model.predict(X_train)))\n",
    "    test_scores.append(accuracy_score(y_test, model.predict(X_test)))\n",
    "\n",
    "plt.plot([str(d) for d in depths], train_scores, marker=\"o\", label=\"Train\")\n",
    "plt.plot([str(d) for d in depths], test_scores, marker=\"o\", label=\"Test\")\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"DecisionTree accuracy vs max_depth\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest accuracy vs n_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [5, 10, 20, 30, 50]\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for n in estimators:\n",
    "    model = RandomForest(n_estimators=n, max_depth=7, criterion=\"gini\", max_features=\"sqrt\")\n",
    "    model.fit(X_train, y_train)\n",
    "    train_scores.append(accuracy_score(y_train, model.predict(X_train)))\n",
    "    test_scores.append(accuracy_score(y_test, model.predict(X_test)))\n",
    "\n",
    "plt.plot(estimators, train_scores, marker=\"o\", label=\"Train\")\n",
    "plt.plot(estimators, test_scores, marker=\"o\", label=\"Test\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"RandomForest accuracy vs n_estimators\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of grid search hyperparameters\n",
    "\n",
    "We test the hyperparameters found by grid search on the full training set and evaluate on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTree\n",
    "dt_best = DecisionTree(**best_dt_params)\n",
    "dt_best.fit(X_train, y_train)\n",
    "dt_pred = dt_best.predict(X_test)\n",
    "dt_acc = accuracy_score(y_test, dt_pred)\n",
    "\n",
    "# RandomForest\n",
    "rf_best = RandomForest(**best_rf_params)\n",
    "rf_best.fit(X_train, y_train)\n",
    "rf_pred = rf_best.predict(X_test)\n",
    "rf_acc = accuracy_score(y_test, rf_pred)\n",
    "\n",
    "# Print accuracy\n",
    "print(f\"DecisionTree test accuracy: {dt_acc:.4f}\")\n",
    "print(f\"RandomForest test accuracy: {rf_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final evaluation\n",
    "\n",
    "Instead of using the grid search hyperparameters, we use the most correct values based on theory and our own analysis (argued in the rapport). Again, we use the full training set and evaluate on the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_manual = DecisionTree(\n",
    "    max_depth=7,\n",
    "    criterion=\"gini\",\n",
    "    max_features=\"sqrt\",\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "dt_manual.fit(X_train, y_train)\n",
    "dt_pred = dt_manual.predict(X_test)\n",
    "dt_acc = accuracy_score(y_test, dt_pred)\n",
    "\n",
    "rf_manual = RandomForest(\n",
    "    n_estimators=30,     \n",
    "    max_depth=7,           \n",
    "    criterion=\"gini\", \n",
    "    max_features=\"sqrt\",\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "rf_manual.fit(X_train, y_train)\n",
    "rf_pred = rf_manual.predict(X_test)\n",
    "rf_acc = accuracy_score(y_test, rf_pred)\n",
    "\n",
    "# Print accuracy\n",
    "print(f\"DecisionTree test accuracy: {dt_acc:.4f}\")\n",
    "print(f\"RandomForest test accuracy: {rf_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKLearn modeller\n",
    "\n",
    "Trener modell med sklearn med de samme paramterene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "sk_dt_manual = DecisionTreeClassifier(\n",
    "    max_depth=5,\n",
    "    criterion=\"gini\",\n",
    "    max_features=\"sqrt\",\n",
    "    random_state=RANDOM_SEED\n",
    "\n",
    ")\n",
    "sk_dt_manual.fit(X_train, y_train)\n",
    "sk_dt_acc = accuracy_score(y_test, sk_dt_manual.predict(X_test))\n",
    "\n",
    "sk_rf_manual = RandomForestClassifier(\n",
    "    n_estimators=30,\n",
    "    max_depth=5,\n",
    "    criterion=\"gini\",\n",
    "    max_features=\"sqrt\",\n",
    "    random_state=RANDOM_SEED\n",
    "\n",
    ")\n",
    "sk_rf_manual.fit(X_train, y_train)\n",
    "sk_rf_acc = accuracy_score(y_test, sk_rf_manual.predict(X_test))\n",
    "\n",
    "# Print accuracy\n",
    "print(f\"Sklearn DecisionTree test accuracy: {sk_dt_acc:.4f}\")\n",
    "print(f\"Sklearn RandomForest test accuracy: {sk_rf_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sammenligner kjøretid av vår kontra SK implementasjon "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# DecisionTree\n",
    "start = time.time()\n",
    "dt_best.fit(X_train, y_train)\n",
    "train_time_dt = time.time() - start\n",
    "\n",
    "start = time.time()\n",
    "_ = dt_best.predict(X_test)\n",
    "pred_time_dt = time.time() - start\n",
    "\n",
    "# RandomForest\n",
    "start = time.time()\n",
    "rf_best.fit(X_train, y_train)\n",
    "train_time_rf = time.time() - start\n",
    "\n",
    "start = time.time()\n",
    "_ = rf_best.predict(X_test)\n",
    "pred_time_rf = time.time() - start\n",
    "\n",
    "# Sklearn DecisionTree\n",
    "start = time.time()\n",
    "sk_dt.fit(X_train, y_train)\n",
    "train_time_dt_sklearn = time.time() - start\n",
    "\n",
    "start = time.time()\n",
    "_ = sk_dt.predict(X_test)\n",
    "pred_time_dt_sklearn = time.time() - start\n",
    "\n",
    "# Sklearn RandomForest\n",
    "start = time.time()\n",
    "sk_rf.fit(X_train, y_train)\n",
    "train_time_rf_sklearn = time.time() - start\n",
    "\n",
    "start = time.time()\n",
    "_ = sk_rf.predict(X_test)\n",
    "pred_time_rf_sklearn = time.time() - start\n",
    "\n",
    "# Put results in a table\n",
    "df_speed = pd.DataFrame({\n",
    "    \"DT\": [train_time_dt, pred_time_dt],\n",
    "    \"Sklearn DT\": [train_time_dt_sklearn, pred_time_dt_sklearn],\n",
    "    \"RF\": [train_time_rf, pred_time_rf],\n",
    "    \"Sklearn RF\": [train_time_rf_sklearn, pred_time_rf_sklearn],\n",
    "}, index=[\"Train time (s)\", \"Predict time (s)\"])\n",
    "\n",
    "print(df_speed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4 - Permutation Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_importance(model, X, y, metric=accuracy_score, n_repeats=30, seed=RANDOM_SEED):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    baseline = metric(y, model.predict(X))\n",
    "    importances = []\n",
    "\n",
    "    for col in range(X.shape[1]):\n",
    "        scores = []\n",
    "        for _ in range(n_repeats):\n",
    "            X_permuted = X.copy()\n",
    "            rng.shuffle(X_permuted[:, col])\n",
    "            score = metric(y, model.predict(X_permuted))\n",
    "            scores.append(baseline - score)\n",
    "        importances.append(np.mean(scores))\n",
    "    return np.array(importances)\n",
    "\n",
    "rf_best = RandomForest(**best_rf_params)\n",
    "rf_best.fit(X_train, y_train)\n",
    "\n",
    "importances = permutation_importance(rf_best, X_test, y_test, n_repeats=30, seed=RANDOM_SEED)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.bar(range(len(feature_names)), importances)\n",
    "plt.xticks(range(len(feature_names)), feature_names, rotation=90)\n",
    "plt.ylabel(\"Permutation importance\")\n",
    "plt.title(\"Feature importance RandomForest\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "INF264",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
