{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1 – Decision Trees and Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload all modules without having to restart the kernel\n",
    "# Useful for development if you have edited any of the external code files.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from itertools import product\n",
    "from decision_tree import DecisionTree\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# ... add more imports as needed\n",
    "\n",
    "# My implementations\n",
    "from decision_tree import DecisionTree\n",
    "from random_forest import RandomForest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset\n",
    "\n",
    "We load the `letters.csv` dataset, separate features and labels, and split into train/test sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1400, 16), y_train shape: (1400,)\n",
      "X_test shape: (600, 16), y_test shape: (600,)\n"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt(\"letters.csv\", delimiter=\",\", dtype=float, names=True)\n",
    "\n",
    "feature_names = list(data.dtype.names[:-1])\n",
    "target_name = data.dtype.names[-1]\n",
    "\n",
    "X = np.array([data[f] for f in feature_names]).T\n",
    "y = data[target_name].astype(int)\n",
    "\n",
    "# Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=0, shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparametere\n",
    "\n",
    "Forklar hva som skjer her."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_params = {\n",
    "    \"criterion\": [\"entropy\", \"gini\"],\n",
    "    \"max_depth\": [None, 5, 10, 20],\n",
    "    \"max_features\": [None, \"sqrt\", \"log2\"]\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    \"n_estimators\": [10, 20, 50],\n",
    "    \"max_depth\": [5, 10, None],\n",
    "    \"criterion\": [\"entropy\", \"gini\"],\n",
    "    \"max_features\": [\"sqrt\", \"log2\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation helper\n",
    "\n",
    "We implement a helper function to evaluate models with k-fold cross-validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_score_custom(model_class, params, X, y, k=5):\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=0)\n",
    "    scores = []\n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = model_class(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "        scores.append(accuracy_score(y_val, y_pred))\n",
    "    return np.mean(scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTree model selection\n",
    "\n",
    "We loop over hyperparameter combinations for our custom DecisionTree, evaluate with cross-validation, and select the best.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DecisionTree.__init__() got an unexpected keyword argument 'max_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m criterion, max_depth, max_features \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[32m      5\u001b[39m     dt_params[\u001b[33m\"\u001b[39m\u001b[33mcriterion\u001b[39m\u001b[33m\"\u001b[39m], dt_params[\u001b[33m\"\u001b[39m\u001b[33mmax_depth\u001b[39m\u001b[33m\"\u001b[39m], dt_params[\u001b[33m\"\u001b[39m\u001b[33mmax_features\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      6\u001b[39m ):\n\u001b[32m      7\u001b[39m     params = {\n\u001b[32m      8\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcriterion\u001b[39m\u001b[33m\"\u001b[39m: criterion,\n\u001b[32m      9\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmax_depth\u001b[39m\u001b[33m\"\u001b[39m: max_depth,\n\u001b[32m     10\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmax_features\u001b[39m\u001b[33m\"\u001b[39m: max_features\n\u001b[32m     11\u001b[39m     }\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     score = \u001b[43mcross_val_score_custom\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDecisionTree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m score > best_dt_score:\n\u001b[32m     14\u001b[39m         best_dt_score = score\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mcross_val_score_custom\u001b[39m\u001b[34m(model_class, params, X, y, k)\u001b[39m\n\u001b[32m      5\u001b[39m X_train, X_val = X[train_idx], X[val_idx]\n\u001b[32m      6\u001b[39m y_train, y_val = y[train_idx], y[val_idx]\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m model = \u001b[43mmodel_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m model.fit(X_train, y_train)\n\u001b[32m     10\u001b[39m y_pred = model.predict(X_val)\n",
      "\u001b[31mTypeError\u001b[39m: DecisionTree.__init__() got an unexpected keyword argument 'max_features'"
     ]
    }
   ],
   "source": [
    "best_dt_params = None\n",
    "best_dt_score = -1\n",
    "\n",
    "for criterion, max_depth, max_features in product(\n",
    "    dt_params[\"criterion\"], dt_params[\"max_depth\"], dt_params[\"max_features\"]\n",
    "):\n",
    "    params = {\n",
    "        \"criterion\": criterion,\n",
    "        \"max_depth\": max_depth,\n",
    "        \"max_features\": max_features\n",
    "    }\n",
    "    score = cross_val_score_custom(DecisionTree, params, X_train, y_train, k=5)\n",
    "    if score > best_dt_score:\n",
    "        best_dt_score = score\n",
    "        best_dt_params = params\n",
    "\n",
    "print(\"Best DecisionTree params:\", best_dt_params)\n",
    "print(\"Best DecisionTree CV accuracy:\", best_dt_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final evaluation\n",
    "\n",
    "We retrain our models with the best hyperparameters on the full training set and evaluate on the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTree\n",
    "dt_best = DecisionTree(**best_dt_params)\n",
    "dt_best.fit(X_train, y_train)\n",
    "dt_test_acc = accuracy_score(y_test, dt_best.predict(X_test))\n",
    "\n",
    "# RandomForest\n",
    "rf_best = RandomForest(**best_rf_params)\n",
    "rf_best.fit(X_train, y_train)\n",
    "rf_test_acc = accuracy_score(y_test, rf_best.predict(X_test))\n",
    "\n",
    "print(\"Custom DecisionTree test accuracy:\", dt_test_acc)\n",
    "print(\"Custom RandomForest test accuracy:\", rf_test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with sklearn\n",
    "\n",
    "We compare our implementations against sklearn’s DecisionTreeClassifier and RandomForestClassifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn DecisionTree\n",
    "sk_dt = DecisionTreeClassifier(\n",
    "    criterion=best_dt_params[\"criterion\"],\n",
    "    max_depth=best_dt_params[\"max_depth\"],\n",
    "    max_features=best_dt_params[\"max_features\"],\n",
    "    random_state=0\n",
    ")\n",
    "sk_dt.fit(X_train, y_train)\n",
    "sk_dt_acc = accuracy_score(y_test, sk_dt.predict(X_test))\n",
    "\n",
    "# Sklearn RandomForest\n",
    "sk_rf = RandomForestClassifier(\n",
    "    n_estimators=best_rf_params[\"n_estimators\"],\n",
    "    max_depth=best_rf_params[\"max_depth\"],\n",
    "    criterion=best_rf_params[\"criterion\"],\n",
    "    max_features=best_rf_params[\"max_features\"],\n",
    "    random_state=0\n",
    ")\n",
    "sk_rf.fit(X_train, y_train)\n",
    "sk_rf_acc = accuracy_score(y_test, sk_rf.predict(X_test))\n",
    "\n",
    "print(\"Sklearn DecisionTree test accuracy:\", sk_dt_acc)\n",
    "print(\"Sklearn RandomForest test accuracy:\", sk_rf_acc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (INF264)",
   "language": "python",
   "name": "inf264"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
